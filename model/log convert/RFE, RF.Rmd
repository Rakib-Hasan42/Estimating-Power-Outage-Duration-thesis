---
title: "RFE, RF"
author: "Rakib"
date: "2025-04-30"
output: html_document
---

#library
```{r}
library(dplyr)
library(caret)
library(scales)
```

#data
```{r}
data <- read.csv("C:/Users/rakib/Desktop/Thesis/DATA/combined final data set/final_data.csv")

data <- data%>%
  select(-c(date, fips_code))
data$log_outage <- log1p(data$total_outage)
data$log_prev_outage <- log1p(data$prev_outage)
data$log_prev_3avg_outage <- log1p(data$prev_3day_avg_outage)
```

#RFE
```{r}
# Define predictors (make sure to exclude target + IDs)
predictor_cols <- setdiff(names(data), c("total_outage", "county", 'event_name', 'prev_outage', 'prev_3day_avg_outage', 'log_outage'))

set.seed(700)
# Control setup
ctrl <- rfeControl(functions = rfFuncs, # use random forest functions
                   method = "cv",       # cross-validation
                   number = 5)          # 5-fold CV


# Run RFE
rfe_model <- rfe(
  x = data[, predictor_cols],
  y = data$log_outage,
  sizes = c(16, 18, 20, 22, 23),         # test different feature set sizes
  rfeControl = ctrl
)

#best subset
predictors(rfe_model)
#Plot Performance vs. Number of Features
plot(rfe_model, type = c("g", "o"))
```
# data split and variable selected
```{r}
#selected variables
selected_vars <- predictors(rfe_model)
set.seed(1)
# Split data into 80% training and 20% testing
train_index <- createDataPartition(data$total_outage, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
```

# Random Forest
```{r}
#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(701)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()

```

# Idalia
```{r}
test_event <- c("idalia")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(702)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Ian
```{r}
test_event <- c("ian")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(703)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Nicole
```{r}
test_event <- c("nicole")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(704)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Sally
```{r}
test_event <- c("sally")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(705)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Eta
```{r}
test_event <- c("eta")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(706)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Elsa
```{r}
test_event <- c("elsa")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(707)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Mindy
```{r}
test_event <- c("mindy")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(708)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```

# Fred
```{r}
test_event <- c("fred")  # for testing

train_data <- data %>%
  filter(!event_name %in% test_event)
test_data <- data %>%
  filter(event_name %in% test_event)

#Tune mtry with Cross-Validation
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  mtry = c(6, 8, 10, 12, 14)
)
set.seed(709)
tuned_rf <- train(
  x = train_data[, selected_vars],
  y = train_data$log_outage,
  method = "rf",
  tuneGrid = tune_grid,
  trControl = ctrl
)
print(tuned_rf)
best_mtry <- tuned_rf$bestTune$mtry
cat("Best mtry:", best_mtry, "\n")
plot(tuned_rf)
#variable imp
varImp(tuned_rf, scale = FALSE)
plot(varImp(tuned_rf, scale = FALSE))
#predict on test data
preds <- predict(tuned_rf, newdata = test_data[, selected_vars])
#antilog
preds <- pmax(expm1(preds), 0) # Avoid negative predictions
actuals <- test_data$total_outage
# Evaluate
results <- postResample(pred = preds, obs = actuals)

# Format results as a data frame
eval_table <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(
    round(results["RMSE"], 2),
    round(results["Rsquared"], 4),
    round(results["MAE"], 2)
  )
)

# Print table
print(eval_table)
#Traditional/Definition based R2
sst <- sum((actuals - mean(actuals))^2)
sse <- sum((actuals - preds)^2)
r2_traditional <- 1 - (sse / sst)
cat("Traditional R-squared:", round(r2_traditional, 4))

#actual vs prediction plot
plot_df <- data.frame(
  actuals = actuals,
  preds = preds
)
ideal_line_df <- data.frame(x = c(0, max(plot_df$actuals)), y = c(0, max(plot_df$actuals)))
ggplot(plot_df, aes(x = actuals, y = preds)) +
  geom_point(aes(color = "Actual vs Predicted Points")) +
  geom_smooth(aes(color = "Regression Line"), method = "lm", se = FALSE) +
   geom_line(data = ideal_line_df, aes(x = x, y = y, color = "Ideal Line"), linetype = "dashed", size = 1) +
  scale_color_manual(
    name = "Legend",
    values = c(
      "Actual vs Predicted Points" = "blue",
      "Regression Line" = "green",
      "Ideal Line" = "red"
    )
  ) +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(
    title = "Actual vs Predicted with Regression Line",
    x = "Actual Outage",
    y = "Predicted Outage",
    color = "Legend"
  ) +
  theme_minimal()
```
